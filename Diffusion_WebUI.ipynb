{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zabinzsur/Collab_WebUI_Inference/blob/main/Diffusion_WebUI.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QOmvhMFXLjbI"
      },
      "source": [
        "# Diffusion WebUI\n",
        "Choose your models and just run it. No extra steps"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "lOC4X1umLtAi"
      },
      "source": [
        "THIS IS A MODIFIED VERSION OF ORIGINAL CODE HERE:\n",
        "### [GitHub](https://github.com/acheong08/NovelAI-Colab)\n",
        "# Quick start: \n",
        "Run the Unified code.\n",
        "\n",
        "(If there are any issues, report them on GitHub)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "twBYi6Y4aj_a"
      },
      "outputs": [],
      "source": [
        "#@title Check dependencies (Run this if you get errors)\n",
        "import os\n",
        "\n",
        "!nvidia-smi\n",
        "!pip install pytorch_lightning\n",
        "import pytorch_lightning as pl\n",
        "print(pl.__version__)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TL9o4lz5XK2y"
      },
      "source": [
        "# Unified code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dtrNFeQiYDz-"
      },
      "outputs": [],
      "source": [
        "#@markdown ## Add models\n",
        "#@markdown - You can run this multiple times to add more models to the list\n",
        "#@markdown - Leave input blank to ignore\n",
        "#@markdown - No spaces allowed in the name\n",
        "\n",
        "try:\n",
        "  customModels\n",
        "except NameError:\n",
        "  customModels = []\n",
        "else:\n",
        "  pass\n",
        "\n",
        "#@markdown ### Custom\n",
        "#@markdown The model URL should be a direct download link or Google Drive URL\n",
        "#@markdown <br> The modelURL should a DIRECT DOWNLOAD LINK.\n",
        "#@markdown <br>https://huggingface.co/ShadoWxShinigamI/MidJourney-PaperCut/blob/main/Mdjrny-pprct_step_7000.ckpt\n",
        "#@markdown <br>is actually supposed to be\n",
        "#@markdown <br>https://huggingface.co/ShadoWxShinigamI/MidJourney-PaperCut/resolve/main/Mdjrny-pprct_step_7000.ckpt\n",
        "modelName = \"\" #@param {'type': 'string'}\n",
        "modelURL = \"\" #@param [\"\", \"https://huggingface.co/ShadoWxShinigamI/MidJourney-PaperCut/resolve/main/Mdjrny-pprct_step_7000.ckpt\", \"https://huggingface.co/hesw23168/SD-Elysium-Model/resolve/main/Elysium_V1.ckpt\", \"https://huggingface.co/acheong08/nutmegmix/resolve/main/nutmegmix.ckpt\", \"https://huggingface.co/hesw23168/SD-Elysium-Model/resolve/main/Elysium_Anime_V2.ckpt\", \"https://huggingface.co/Linaqruf/anything-v3.0/resolve/main/Anything-V3.0-pruned.ckpt\", \"https://huggingface.co/prompthero/linkedin-diffusion/resolve/main/lnkdn.ckpt\"] {allow-input: true}\n",
        "\n",
        "#@markdown ## Defaults\n",
        "#@markdown SDv2.0 and mdjrny-v4 style has been added\n",
        "defaultModelURLs = [\"\" ,\"https://huggingface.co/acheong08/secretAI/resolve/main/stableckpt/animefull-final-pruned/model.ckpt\", \"https://huggingface.co/Zabin/Stable-Diffusion-InkPunk/resolve/main/novelInkpunkF222_v1.ckpt\", \"https://huggingface.co/hakurei/waifu-diffusion-v1-3/resolve/main/wd-v1-3-float32.ckpt\", \"https://huggingface.co/Fictiverse/Stable_Diffusion_VoxelArt_Model/resolve/main/VoxelArt_v1.ckpt\", \"https://huggingface.co/runwayml/stable-diffusion-v1-5/resolve/main/v1-5-pruned-emaonly.ckpt\", \"https://huggingface.co/runwayml/stable-diffusion-inpainting/resolve/main/sd-v1-5-inpainting.ckpt\", \"https://huggingface.co/acheong08/f222/resolve/main/f222.ckpt\", \"https://huggingface.co/Zabin/Stable-Diffusion-InkPunk/resolve/main/synthwavePunk_v2.ckpt\", \"https://huggingface.co/nitrosocke/Ghibli-Diffusion/resolve/main/ghibli-diffusion-v1.ckpt\", \"https://huggingface.co/acheong08/HassansBlend/resolve/main/HassansBlend.ckpt\", \"https://huggingface.co/stabilityai/stable-diffusion-2-1/resolve/main/v2-1_768-ema-pruned.ckpt\", \"https://huggingface.co/Zabin/Stable-Diffusion-InkPunk/resolve/main/comodel2.ckpt\", \"https://huggingface.co/prompthero/openjourney/resolve/main/mdjrny-v4.ckpt\", \"https://huggingface.co/Zabin/Stable-Diffusion-InkPunk/resolve/main/elldrethSLucidMix_v10.safetensors\", \"https://huggingface.co/AmethystVera/SimpMaker-3K1/resolve/main/SimpMaker%203k1.ckpt\", \"https://huggingface.co/speedrunner/atitanstrawberry/resolve/main/ATitanStrawBerry.ckpt\", \"https://huggingface.co/dreamlike-art/dreamlike-diffusion-1.0/resolve/main/dreamlike-diffusion-1.0.ckpt\", \"https://huggingface.co/Sandro-Halpo/SamDoesArt-V3/blob/main/SamDoesArt-V3.safetensors\", \"https://huggingface.co/Zabin/Stable-Diffusion-InkPunk/resolve/main/attractiveWomen_attrMixV2.safetensors\"]\n",
        "defaultModels = [\"\" ,\"NovelAI\", \"NovelInkpunkF222\", \"WaifuDiffusion\", \"VoxelArtModel\", \"SD1-5\", \"SD-inpainting\", \"f222-NSFW\", \"SynthwavePunk_v2\", \"Ghibli\", \"HassansBlend\", \"SDv2-1\", \"Cmodel2.1\", \"OpenMidjourney\", \"EldrethsLucidMix\", \"SimpMaker3k1\", \"ATitanStrawBerry\", \"Dreamlike\", \"SamDoesArt\", \"AttractiveWomen\"]\n",
        "defaultModel = \"\" #@param [\"\" ,\"NovelAI\", \"NovelInkpunkF222\", \"WaifuDiffusion\", \"VoxelArtModel\", \"SD1-5\", \"SD-inpainting\", \"f222-NSFW\", \"SynthwavePunk_v2\", \"Ghibli\", \"HassansBlend\", \"SDv2-1\", \"Cmodel2.1\", \"OpenMidjourney\", \"EldrethsLucidMix\", \"SimpMaker3k1\", \"ATitanStrawBerry\", \"Dreamlike\", \"SamDoesArt\" , \"AttractiveWomen\" ]\n",
        "\n",
        "#@markdown # Parameters\n",
        "#@markdown Select this if the model is based on SD2.0\n",
        "SD2 = \"None\" #@param [\"None\", \"V2-512\", \"V2-768\", \"V2-inpainting\", \"V2-upscaling\"]\n",
        "\n",
        "if modelName == \"\" or modelURL == \"\":\n",
        "  pass\n",
        "else:\n",
        "  if modelURL.endswith(\"safetensors\"):\n",
        "    modelName = modelName + \".safetensors\"\n",
        "  else:\n",
        "    modelName = modelName + \".ckpt\"\n",
        "  customModels.append((modelName, modelURL, SD2))\n",
        "\n",
        "if defaultModel != \"\":\n",
        "  if defaultModelURLs[defaultModels.index(defaultModel)].endswith(\"safetensors\"):\n",
        "    defaultModelName = defaultModel + \".safetensors\"\n",
        "  else:\n",
        "    defaultModelName = defaultModel + \".ckpt\"\n",
        "  # Map model to URL\n",
        "  customModels.append((defaultModelName, defaultModelURLs[defaultModels.index(defaultModel)], SD2))\n",
        "\n",
        "print(customModels)\n",
        "from IPython import display\n",
        "display.HTML(\"<p>Want faster speed? <a href=\\\"https://www.youtube.com/watch?v=dQw4w9WgXcQ\\\">Here</a>'s a better version of this Colab!</p>\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "LEPOSoQ3_xNT"
      },
      "outputs": [],
      "source": [
        "#@markdown ## Clear model list\n",
        "customModels = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "Y4qjIc1XXKWw"
      },
      "outputs": [],
      "source": [
        "#@title Start WebUI\n",
        "#@markdown # Instructions:\n",
        "#@markdown Select your favorite model (Or all of them)\n",
        "#@markdown 0. Set models in the cell above\n",
        "#@markdown 1. Run this cell.\n",
        "#@markdown  <br> - Ignore alerts about disk space. You got plenty\n",
        "#@markdown 2. Wait\n",
        "#@markdown 3. Open gradio link\n",
        "\n",
        "#@markdown #### The default username is `webui` and password is `diffusion`\n",
        "\n",
        "#@markdown If you encounter any errors, you should check out the [stable](https://colab.research.google.com/drive/1LACPou7-Oorqun08lhHr-SO8b2F4zlob#scrollTo=Y4qjIc1XXKWw) version of this colab.\n",
        "\n",
        "!pip3 install triton --quiet\n",
        "!pip3 install pytorch_lightning --quiet\n",
        "!pip install --upgrade --no-cache-dir gdown httplib2 --quiet\n",
        "\n",
        "#@markdown # Options\n",
        "from google.colab import drive\n",
        "import os\n",
        "import time\n",
        "from subprocess import getoutput\n",
        "\n",
        "vae_args = \"\"\n",
        "#@markdown Running in Google Drive prevents updates and is not recommended\n",
        "run_in_gdrive = False #@param {'type':'boolean'}\n",
        "\n",
        "root_dir = \"/content\"\n",
        "\n",
        "if run_in_gdrive:\n",
        "  drive.mount('/content/drive')\n",
        "  !mkdir -p {'/content/drive/MyDrive/AI'}\n",
        "  root_dir = \"/content/drive/MyDrive/AI\"\n",
        "else:\n",
        "  root_dir = \"/content\"\n",
        "\n",
        "%cd {root_dir}\n",
        "\n",
        "def get_hypernetworks():\n",
        "  !mkdir -p {root_dir}/stable-diffusion-webui/models/hypernetworks\n",
        "  hypernetworks = ['anime_2.pt', 'anime.pt', 'anime_3.pt', 'furry_2.pt', 'furry_3.pt', 'furry_protogen.pt', 'furry_transformation.pt', 'furry_scalie.pt', 'pony.pt', 'aini.pt', 'furry.pt', 'furry_kemono.pt']\n",
        "  for network in hypernetworks:\n",
        "    !wget -c https://huggingface.co/acheong08/secretAI/resolve/main/stableckpt/modules/modules/{network} -O {root_dir}/stable-diffusion-webui/models/hypernetworks/{network}\n",
        "\n",
        "def install_aria():\n",
        "  if not os.path.exists('/usr/bin/aria2c'):\n",
        "    !apt install -y -qq aria2\n",
        "\n",
        "def custom_model(checkpoint_name, url, SD2):\n",
        "  inference_url = \"https://raw.githubusercontent.com/Stability-AI/stablediffusion/main/configs/stable-diffusion/\"\n",
        "  if SD2 == \"V2-768\":\n",
        "    inference_url += \"v2-inference-v.yaml\"\n",
        "  elif SD2 == \"V2-512\":\n",
        "    inference_url += \"v2-inference.yaml\"\n",
        "  elif SD2 == \"V2-inpainting\":\n",
        "    inference_url += \"v2-inpainting-inference.yaml\"\n",
        "  elif SD2 == \"V2-upscaling\":\n",
        "    inference_url += \"x4-upscaling.yaml\"\n",
        "    \n",
        "  if SD2.startswith(\"V2\"):\n",
        "    checkpoint_config = checkpoint_name.split('.')[0]\n",
        "    !wget {inference_url} -O {root_dir}/stable-diffusion-webui/models/Stable-diffusion/{checkpoint_config}.yaml\n",
        "\n",
        "  if url.startswith(\"https://drive.google.com\"):\n",
        "    !gdown --fuzzy -O \"{root_dir}/stable-diffusion-webui/models/Stable-diffusion/{checkpoint_name}\" \"{url}\"\n",
        "  elif url.startswith(\"magnet:?\"):\n",
        "    install_aria()\n",
        "    !aria2c --summary-interval=10 -c -x 10 -k 1M -s 10 -o {root_dir}/stable-diffusion-webui/models/Stable-diffusion/{checkpoint_name} \"{url}\"\n",
        "  else:\n",
        "    #@markdown You can use the default token or enter your own for private models\n",
        "    user_token = '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' #@param {'type': 'string'}\n",
        "    user_header = f\"\\\"Authorization: Bearer {user_token}\\\"\"\n",
        "    !wget -c --header={user_header} {url} -O {root_dir}/stable-diffusion-webui/models/Stable-diffusion/{checkpoint_name}\n",
        "\n",
        "def install_xformers():\n",
        "  !pip install https://github.com/camenduru/stable-diffusion-webui-colab/releases/download/0.0.15/xformers-0.0.15.dev0+189828c.d20221207-cp38-cp38-linux_x86_64.whl --quiet\n",
        "\n",
        "def install_deps():\n",
        "  %cd {root_dir}\n",
        "  !git clone https://github.com/acheong08/stable-diffusion-webui\n",
        "  %cd {root_dir}/stable-diffusion-webui/\n",
        "  !git pull\n",
        "  %cd {root_dir}\n",
        "  use_hypernetworks = False #@param {'type':'boolean'}\n",
        "\n",
        "  # Get models\n",
        "  for model in customModels:\n",
        "    custom_model(model[0], model[1], model[2])\n",
        "  if use_hypernetworks:\n",
        "    get_hypernetworks()\n",
        "  \n",
        "  %cd {root_dir}/stable-diffusion-webui/extensions\n",
        "  !git clone https://github.com/yfszzx/stable-diffusion-webui-images-browser\n",
        "  %cd {root_dir}\n",
        "\n",
        "def run_webui():\n",
        "  vae = \"\" #@param [\"\", \"Anime\", \"Stable Diffusion\"]\n",
        "  if vae == \"Anime\":\n",
        "    !wget -c https://huggingface.co/acheong08/secretAI/resolve/main/stableckpt/animevae.pt -O {root_dir}/stable-diffusion-webui/models/Stable-diffusion/novelAI.vae.pt\n",
        "    vae_args = \"--vae-path \" + root_dir + \"/stable-diffusion-webui/models/Stable-diffusion/novelAI.vae.pt\"\n",
        "  elif vae == \"Stable Diffusion\":\n",
        "    !wget -c https://huggingface.co/stabilityai/sd-vae-ft-mse-original/resolve/main/vae-ft-mse-840000-ema-pruned.ckpt -O {root_dir}/stable-diffusion-webui/models/Stable-diffusion/sd-v1-5.vae.pt\n",
        "    vae_args = \"--vae-path \" + root_dir + \"/stable-diffusion-webui/models/Stable-diffusion/sd-v1-5.vae.pt\"\n",
        "\n",
        "  %cd {root_dir}/stable-diffusion-webui/\n",
        "  vram = \"\" #@param [\"--medvram\", \"--lowvram\", \"\"]\n",
        "  other_args = \"--share --xformers --enable-insecure-extension-access\" #@param [\"--share\", \"--share --xformers\"] {'allow-input': true}\n",
        "  xformers = True #@param {'type': 'boolean'}\n",
        "  gradio_username = \"webui\" #@param {'type': 'string'}\n",
        "  gradio_password = \"diffusion\" #@param {'type': 'string'}\n",
        "  #@markdown Tick this if you will be handling models greater than 7GB or merging multiple models\n",
        "  large_models = False #@param {'type': 'boolean'}\n",
        "  if xformers:\n",
        "    install_xformers()\n",
        "  if large_models:\n",
        "    %cd /content/stable-diffusion-webui\n",
        "    !sed -i \"s/'cpu'/devices.get_optimal_device()/g\" modules/extras.py\n",
        "    vram = \"--lowvram\"\n",
        "  !COMMANDLINE_ARGS=\"{other_args} {vae_args} {vram} --gradio-auth {gradio_username}:{gradio_password}\" REQS_FILE=\"requirements.txt\" python launch.py\n",
        "\n",
        "install_deps()\n",
        "run_webui()\n",
        "#@markdown # Common issues\n",
        "#@markdown ### Why am I getting low quality limages?\n",
        "#@markdown NovelAI uses a different system for interpreting prompts than Stable Diffusion. Check out gelbooru.com's tags (NSFW)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_xPLSbzNTgF2"
      },
      "source": [
        "## Saving your images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "lpiP4AkYTic0"
      },
      "outputs": [],
      "source": [
        "#@markdown Download file manually from files tab or save to Google Drive\n",
        "%cd /content/stable-diffusion-webui/\n",
        "!zip -r /content/output.zip outputs\n",
        "\n",
        "from pydrive.auth import GoogleAuth\n",
        "from google.colab import drive\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "def create_folder(folder_name):\n",
        "    # Check if folder exists\n",
        "    file_list = drive.ListFile({'q': \"title='{}' and mimeType='application/vnd.google-apps.folder' and trashed=false\".format(folder_name)}).GetList()\n",
        "    if len(file_list) > 0:\n",
        "        # Folder exists\n",
        "        print('Debug: Folder exists')\n",
        "        folder_id = file_list[0]['id']\n",
        "    else:\n",
        "        print('Debug: Creating folder')\n",
        "        file = drive.CreateFile({'title': folder_name, 'mimeType': 'application/vnd.google-apps.folder'})\n",
        "        file.Upload()\n",
        "        folder_id = file.attr['metadata']['id']\n",
        "    # return folder id\n",
        "    return folder_id\n",
        "# Upload file to Google Drive\n",
        "def upload_file(file_name, folder_id, save_as):\n",
        "    # Check if file exists\n",
        "    file_list = drive.ListFile({'q': \"title='{}' and trashed=false\".format(save_as)}).GetList()\n",
        "    if len(file_list) > 0:\n",
        "        print('Debug: File already exists')\n",
        "        # Change file name to avoid overwriting\n",
        "        save_as = save_as + ' (1)'\n",
        "    file = drive.CreateFile({'title': save_as, 'parents': [{'id': folder_id}]})\n",
        "    file.SetContentFile(file_name)\n",
        "    # Upload and set permission to public\n",
        "    file.Upload()\n",
        "    file.InsertPermission({'type': 'anyone', 'value': 'anyone', 'role': 'reader'})\n",
        "    # return file id\n",
        "    return file.attr['metadata']['id']\n",
        "\n",
        "use_drive = True #@param {type:\"boolean\"}\n",
        "folder_name = \"AI_pic_archive\" #@param {type: \"string\"}\n",
        "save_as = \"oni.zip\" #@param {type: \"string\"}\n",
        "\n",
        "if use_drive:\n",
        "  auth.authenticate_user()\n",
        "  gauth = GoogleAuth()\n",
        "  gauth.credentials = GoogleCredentials.get_application_default()\n",
        "  drive = GoogleDrive(gauth)\n",
        "  file_id = upload_file('/content/output.zip', create_folder(folder_name), save_as)\n",
        "  print(\"Your sharing link: https://drive.google.com/file/d/\" + file_id + \"/view?usp=sharing\")  "
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "include_colab_link": true,
      "private_outputs": true,
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
