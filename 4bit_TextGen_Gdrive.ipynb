{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zabinzsur/Collab_WebUI_Inference/blob/main/4bit_TextGen_Gdrive.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LLM text generation notebook for Google Colab\n",
        "\n",
        "This notebook uses [https://github.com/oobabooga/text-generation-webui](https://github.com/oobabooga/text-generation-webui) to run conversational models in chat mode.\n",
        "\n",
        "Run all the cells and a public gradio URL will appear at the bottom in around 5 minutes.\n",
        "\n",
        "https://status.gradio.app/\n",
        "\n",
        "## Parameters\n",
        "\n",
        "* **save_logs_to_google_drive**: saves your chat logs, characters, and softprompts to Google Drive automatically, so that they will persist across sessions.\n",
        "* **text_streaming**: streams the text output in real time instead of waiting for the full response to be completed.\n",
        "* **cai_chat**: makes the interface look like Character.AI. Otherwise, it looks like a standard WhatsApp-like chat.\n",
        "* **load_in_8bit**: loads the model with 8-bit precision, reducing the GPU memory usage by half. This allows you to use the full 2048 prompt length without running out of memory, at a small accuracy and speed cost.\n",
        "* **activate_silero_text_to_speech**: responses will be audios instead of text. There are 118 voices available (`en_0` to `en_117`), which can be set in the \"Extensions\" tab of the interface. You can find samples here: [Silero samples](https://oobabooga.github.io/silero-samples/).\n",
        "* **activate_sending_pictures**: adds a menu for sending pictures to the bot, which are automatically captioned using BLIP.\n",
        "* **activate_character_bias**: an extension that adds an user-defined, hidden string at the beginning of the bot's reply with the goal of biasing the rest of the response.\n",
        "* **chat_language**: if different than English, activates automatic translation using Google Translate, allowing you to communicate with the bot in a different language.\n",
        "\n",
        "## Characters\n",
        "\n",
        "You can use the following websites to create characters compatible with this web UI:\n",
        "\n",
        "* [JSON character creator](https://oobabooga.github.io/character-creator.html)\n",
        "* [AI Character Editor](https://zoltanai.github.io/character-editor/)\n",
        "\n",
        "## Credits\n",
        "\n",
        "Based on the [original notebook by 81300](https://colab.research.google.com/github/81300/AI-Notebooks/blob/main/Colab-TextGen-GPU.ipynb).\n"
      ],
      "metadata": {
        "id": "MFQl6-FjSYtY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 1. Keep this tab alive to prevent Colab from disconnecting you { display-mode: \"form\" }\n",
        "\n",
        "#@markdown Press play on the music player that will appear below:\n",
        "%%html\n",
        "<audio src=\"https://oobabooga.github.io/silence.m4a\" controls>"
      ],
      "metadata": {
        "id": "f7TVVj_z4flw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 2. Install the web UI\n",
        "#remember gradio is currently held back\n",
        "save_logs_to_google_drive = False #@param {type:\"boolean\"} \n",
        "save_everything_to_google_drive = False #@param {type:\"boolean\"} \n",
        "#@markdown remember these models are large and free Gdrive is only 15Ggb <br>\n",
        "install_gptq = True #@param {type:\"boolean\"}\n",
        "#@markdown Install GPTQ-for-LLaMa for 4bit quantized models requiring --wbits 4\n",
        "from IPython.display import clear_output\n",
        "if save_logs_to_google_drive:\n",
        "  import os\n",
        "  import shutil\n",
        "  from google.colab import drive\n",
        "  drive.mount('/content/drive')\n",
        "  base_folder = '/content/drive/MyDrive'\n",
        "\n",
        "if save_everything_to_google_drive:\n",
        "    import os\n",
        "    import shutil\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "    base_folder = '/content/drive/MyDrive'\n",
        "    repo_dir = '/content/drive/MyDrive/text-generation-webui'\n",
        "    model_dir = '/content/drive/MyDrive/text-generation-webui/models'\n",
        "    gptq_dir = '/content/drive/MyDrive/text-generation-webui/repositories/GPTQ-for-LLaMa'\n",
        "    if os.path.exists(repo_dir):\n",
        "        %cd {repo_dir}\n",
        "        !git pull\n",
        "    else:\n",
        "        %cd /content/drive/MyDrive/\n",
        "        !git clone https://github.com/oobabooga/text-generation-webui\n",
        "\n",
        "else:\n",
        "    model_dir = '/content/text-generation-webui/models'\n",
        "    repo_dir = '/content/text-generation-webui'\n",
        "    %cd /content\n",
        "    !git clone https://github.com/oobabooga/text-generation-webui\n",
        "\n",
        "\n",
        "\n",
        "if save_logs_to_google_drive:\n",
        "  if not os.path.exists(f\"{base_folder}/oobabooga-data\"):\n",
        "    os.mkdir(f\"{base_folder}/oobabooga-data\")\n",
        "  if not os.path.exists(f\"{base_folder}/oobabooga-data/logs\"):\n",
        "    os.mkdir(f\"{base_folder}/oobabooga-data/logs\")\n",
        "  if not os.path.exists(f\"{base_folder}/oobabooga-data/softprompts\"):\n",
        "    os.mkdir(f\"{base_folder}/oobabooga-data/softprompts\")\n",
        "  if not os.path.exists(f\"{base_folder}/oobabooga-data/characters\"):\n",
        "    shutil.move(\"text-generation-webui/characters\", f\"{base_folder}/oobabooga-data/characters\")\n",
        "  else:\n",
        "    !rm -r \"text-generation-webui/characters\"\n",
        "    \n",
        "  !rm -r \"text-generation-webui/softprompts\"\n",
        "  !ln -s \"$base_folder/oobabooga-data/logs\" \"text-generation-webui/logs\"\n",
        "  !ln -s \"$base_folder/oobabooga-data/softprompts\" \"text-generation-webui/softprompts\"\n",
        "  !ln -s \"$base_folder/oobabooga-data/characters\" \"text-generation-webui/characters\"\n",
        "\n",
        "else:\n",
        "  !mkdir text-generation-webui/logs\n",
        "\n",
        "!ln -s text-generation-webui/logs .\n",
        "!ln -s text-generation-webui/characters .\n",
        "!ln -s text-generation-webui/models .\n",
        "%rm -r sample_data\n",
        "%cd text-generation-webui\n",
        "!wget https://raw.githubusercontent.com/pcrii/Philo-Colab-Collection/main/settings-colab-template.json -O settings-colab-template.json\n",
        "\n",
        "# Install requirements\n",
        "!pip install -r requirements.txt\n",
        "!pip install -r extensions/google_translate/requirements.txt\n",
        "!pip install -r extensions/silero_tts/requirements.txt\n",
        "print(f\"\\033[1;32;1m\\n --> If you see a warning about \\\"pydevd_plugins\\\", just ignore it and move on to Step 3. There is no need to restart the runtime.\\n\\033[0;37;0m\")\n",
        "\n",
        "if install_gptq:\n",
        "    if save_everything_to_google_drive:\n",
        "        if os.path.exists(gptq_dir):\n",
        "            %cd {gptq_dir}\n",
        "            !git pull\n",
        "            !pip install ninja\n",
        "            !pip install -r requirements.txt\n",
        "            !python setup_cuda.py install\n",
        "\n",
        "        else:\n",
        "            !mkdir /content/drive/MyDrive/text-generation-webui/repositories\n",
        "            %cd /content/drive/MyDrive/text-generation-webui/repositories\n",
        "            !git clone https://github.com/oobabooga/GPTQ-for-LLaMa.git -b cuda\n",
        "            %cd GPTQ-for-LLaMa\n",
        "            !pip install ninja\n",
        "            !pip install -r requirements.txt\n",
        "            !python setup_cuda.py install\n",
        "    else:\n",
        "        %mkdir /content/text-generation-webui/repositories/\n",
        "        %cd /content/text-generation-webui/repositories/\n",
        "        !git clone https://github.com/oobabooga/GPTQ-for-LLaMa.git -b cuda\n",
        "        %cd GPTQ-for-LLaMa\n",
        "        !pip install ninja\n",
        "        !pip install -r requirements.txt\n",
        "        !python setup_cuda.py install\n",
        "clear_output()\n",
        "print(\"Finished\")"
      ],
      "metadata": {
        "id": "LGQ8BiMuXMDG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Download Model\n",
        "#@markdown you can insert any huggingface model in Organization/model format\n",
        "model_download = \"anon8231489123/vicuna-13b-GPTQ-4bit-128g\" #@param [ \"facebook/opt-1.3b\", \"anon8231489123/gpt4-x-alpaca-13b-native-4bit-128g\", \"anon8231489123/vicuna-13b-GPTQ-4bit-128g\"] {allow-input: true}\n",
        "#@markdown  Download the model\n",
        "%cd {repo_dir}\n",
        "!python download-model.py {model_download}\n",
        "#this lists directorys from your model folder you can copy the name provided for the model you want for use in the the next cell\n",
        "!rm {model_dir}/place-your-models-here.txt\n",
        "clear_output()\n",
        "if save_logs_to_google_drive or save_everything_to_google_drive:\n",
        "    drive_NOT_mounted = False\n",
        "else:\n",
        "    drive_NOT_mounted = True\n",
        "\n",
        "if drive_NOT_mounted:\n",
        "  import os\n",
        "print(\"Available Models\")\n",
        "print(os.listdir(model_dir))\n",
        "\n"
      ],
      "metadata": {
        "id": "E7t4QfXf4U9p",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 3. Launch\n",
        "\n",
        "import json\n",
        "\n",
        "#@markdown if you dont know what to enter the previous cell should have printed available inputs <br> paste it here\n",
        "model_load = \"anon8231489123_vicuna-13b-GPTQ-4bit-128g\" #@param {type:\"string\"}\n",
        "# Parameters\n",
        "#auto_devices = False #@param {type:\"boolean\"}\n",
        "load_4bit_models = True #@param {type:\"boolean\"}\n",
        "\n",
        "groupsize_128 = True #@param {type:\"boolean\"}\n",
        "load_in_8bit = False #@param {type:\"boolean\"}\n",
        "chat = True #@param {type:\"boolean\"}\n",
        "\n",
        "text_streaming = True #@param {type:\"boolean\"}\n",
        "activate_silero_text_to_speech = False #@param {type:\"boolean\"}\n",
        "activate_sending_pictures = False #@param {type:\"boolean\"}\n",
        "activate_character_bias = False #@param {type:\"boolean\"}\n",
        "chat_language = \"English\" # @param ['Afrikaans', 'Albanian', 'Amharic', 'Arabic', 'Armenian', 'Azerbaijani', 'Basque', 'Belarusian', 'Bengali', 'Bosnian', 'Bulgarian', 'Catalan', 'Cebuano', 'Chinese (Simplified)', 'Chinese (Traditional)', 'Corsican', 'Croatian', 'Czech', 'Danish', 'Dutch', 'English', 'Esperanto', 'Estonian', 'Finnish', 'French', 'Frisian', 'Galician', 'Georgian', 'German', 'Greek', 'Gujarati', 'Haitian Creole', 'Hausa', 'Hawaiian', 'Hebrew', 'Hindi', 'Hmong', 'Hungarian', 'Icelandic', 'Igbo', 'Indonesian', 'Irish', 'Italian', 'Japanese', 'Javanese', 'Kannada', 'Kazakh', 'Khmer', 'Korean', 'Kurdish', 'Kyrgyz', 'Lao', 'Latin', 'Latvian', 'Lithuanian', 'Luxembourgish', 'Macedonian', 'Malagasy', 'Malay', 'Malayalam', 'Maltese', 'Maori', 'Marathi', 'Mongolian', 'Myanmar (Burmese)', 'Nepali', 'Norwegian', 'Nyanja (Chichewa)', 'Pashto', 'Persian', 'Polish', 'Portuguese (Portugal, Brazil)', 'Punjabi', 'Romanian', 'Russian', 'Samoan', 'Scots Gaelic', 'Serbian', 'Sesotho', 'Shona', 'Sindhi', 'Sinhala (Sinhalese)', 'Slovak', 'Slovenian', 'Somali', 'Spanish', 'Sundanese', 'Swahili', 'Swedish', 'Tagalog (Filipino)', 'Tajik', 'Tamil', 'Telugu', 'Thai', 'Turkish', 'Ukrainian', 'Urdu', 'Uzbek', 'Vietnamese', 'Welsh', 'Xhosa', 'Yiddish', 'Yoruba', 'Zulu']\n",
        "\n",
        "\n",
        "activate_google_translate = (chat_language != \"English\")\n",
        "\n",
        "language_codes = {'Afrikaans': 'af', 'Albanian': 'sq', 'Amharic': 'am', 'Arabic': 'ar', 'Armenian': 'hy', 'Azerbaijani': 'az', 'Basque': 'eu', 'Belarusian': 'be', 'Bengali': 'bn', 'Bosnian': 'bs', 'Bulgarian': 'bg', 'Catalan': 'ca', 'Cebuano': 'ceb', 'Chinese (Simplified)': 'zh-CN', 'Chinese (Traditional)': 'zh-TW', 'Corsican': 'co', 'Croatian': 'hr', 'Czech': 'cs', 'Danish': 'da', 'Dutch': 'nl', 'English': 'en', 'Esperanto': 'eo', 'Estonian': 'et', 'Finnish': 'fi', 'French': 'fr', 'Frisian': 'fy', 'Galician': 'gl', 'Georgian': 'ka', 'German': 'de', 'Greek': 'el', 'Gujarati': 'gu', 'Haitian Creole': 'ht', 'Hausa': 'ha', 'Hawaiian': 'haw', 'Hebrew': 'iw', 'Hindi': 'hi', 'Hmong': 'hmn', 'Hungarian': 'hu', 'Icelandic': 'is', 'Igbo': 'ig', 'Indonesian': 'id', 'Irish': 'ga', 'Italian': 'it', 'Japanese': 'ja', 'Javanese': 'jw', 'Kannada': 'kn', 'Kazakh': 'kk', 'Khmer': 'km', 'Korean': 'ko', 'Kurdish': 'ku', 'Kyrgyz': 'ky', 'Lao': 'lo', 'Latin': 'la', 'Latvian': 'lv', 'Lithuanian': 'lt', 'Luxembourgish': 'lb', 'Macedonian': 'mk', 'Malagasy': 'mg', 'Malay': 'ms', 'Malayalam': 'ml', 'Maltese': 'mt', 'Maori': 'mi', 'Marathi': 'mr', 'Mongolian': 'mn', 'Myanmar (Burmese)': 'my', 'Nepali': 'ne', 'Norwegian': 'no', 'Nyanja (Chichewa)': 'ny', 'Pashto': 'ps', 'Persian': 'fa', 'Polish': 'pl', 'Portuguese (Portugal, Brazil)': 'pt', 'Punjabi': 'pa', 'Romanian': 'ro', 'Russian': 'ru', 'Samoan': 'sm', 'Scots Gaelic': 'gd', 'Serbian': 'sr', 'Sesotho': 'st', 'Shona': 'sn', 'Sindhi': 'sd', 'Sinhala (Sinhalese)': 'si', 'Slovak': 'sk', 'Slovenian': 'sl', 'Somali': 'so', 'Spanish': 'es', 'Sundanese': 'su', 'Swahili': 'sw', 'Swedish': 'sv', 'Tagalog (Filipino)': 'tl', 'Tajik': 'tg', 'Tamil': 'ta', 'Telugu': 'te', 'Thai': 'th', 'Turkish': 'tr', 'Ukrainian': 'uk', 'Urdu': 'ur', 'Uzbek': 'uz', 'Vietnamese': 'vi', 'Welsh': 'cy', 'Xhosa': 'xh', 'Yiddish': 'yi', 'Yoruba': 'yo', 'Zulu': 'zu'}\n",
        "\n",
        "\n",
        "%cd {repo_dir}\n",
        "# Applying the selected language and setting the prompt size to 2048\n",
        "# if 8bit mode is selected\n",
        "j = json.loads(open('settings-colab-template.json', 'r').read())\n",
        "j[\"google_translate-language string\"] = language_codes[chat_language]\n",
        "if load_in_8bit:\n",
        "  j[\"chat_prompt_size\"] = 2048\n",
        "with open('settings-colab.json', 'w') as f:\n",
        "  f.write(json.dumps(j, indent=4))\n",
        "\n",
        "params = set()\n",
        "if chat:\n",
        "  params.add('--cai-chat')\n",
        "\n",
        "if load_in_8bit:\n",
        "  params.add('--load-in-8bit')\n",
        "#if auto_devices:\n",
        "#  params.add('--auto-devices')\n",
        "if load_4bit_models:\n",
        "  params.add('--wbits 4')\n",
        "\n",
        "if groupsize_128:\n",
        "  params.add('--groupsize 128')\n",
        "\n",
        "active_extensions = []\n",
        "if activate_sending_pictures:\n",
        "  active_extensions.append('send_pictures')\n",
        "if activate_character_bias:\n",
        "  active_extensions.append('character_bias')\n",
        "if activate_google_translate:\n",
        "  active_extensions.append('google_translate')\n",
        "if activate_silero_text_to_speech:\n",
        "  active_extensions.append('silero_tts')\n",
        "active_extensions.append('gallery')\n",
        "\n",
        "if len(active_extensions) > 0:\n",
        "  params.add(f'--extensions {\" \".join(active_extensions)}')\n",
        "\n",
        "if not text_streaming or activate_google_translate or activate_silero_text_to_speech:\n",
        "  params.add('--no-stream')\n",
        "if activate_character_bias:\n",
        "  params.add('--verbose')\n",
        "\n",
        "# Starting the web UI\n",
        "cmd = f\"python server.py --share --model {model_load} --settings settings-colab.json {' '.join(params)}\"\n",
        "print(cmd)\n",
        "!$cmd"
      ],
      "metadata": {
        "id": "hKuocueuXnm5",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title optional install \"LLaMa\" character file i found on reddit\n",
        "!wget https://github.com/pcrii/Philo-Colab-Collection/raw/main/llama.json \n",
        "!mv llama.json {repo_dir}/characters\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "xkDjS3c8Pr_3"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}